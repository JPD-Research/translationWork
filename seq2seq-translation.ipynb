{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Text translation using seq2seq architectures\n",
    " \n",
    "Based on Tensorflow tutorial [Neural machine translation with attention](https://www.tensorflow.org/text/tutorials/nmt_with_attention)\n",
    "\n",
    "Training a sequence-to-sequence (seq2seq) model similar to from [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025v5)\n",
    "\n",
    "- not the most current architecture, but a good learning step for seq2seq models and attention before moving to Transformers\n",
    "- will allow direct Spanish-English translation\n",
    "- exports model as a tf.saved_model for use in other environments\n",
    "- attention plot is more interesting than the resulting output - shows what parts of the input sentence \"has the model's attention\" while translating\n",
    "\n",
    "With modifications described along the way...this does not currently leverage any available GPU, but will by the time we're done...\n",
    "\n",
    "## Step 0 - Environment Setup \n",
    "\n",
    "assumes tensorflow-text >= 2.10, matplotlib and einops are installed in the environment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1848aefbeef98104"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import typing\n",
    "from typing import Any, Tuple\n",
    "\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:52.165302200Z",
     "start_time": "2023-12-19T20:49:42.652844400Z"
    }
   },
   "id": "d80e9a5a8caee092"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "local_data_path_root = \"C:/LocalResearch/JPD-Research/translationWork\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:52.180795200Z",
     "start_time": "2023-12-19T20:49:52.168796800Z"
    }
   },
   "id": "101d797542de6578"
  },
  {
   "cell_type": "markdown",
   "source": [
    "include helper class to check shapes correctly:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d77d8451ed035302"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class ShapeChecker():\n",
    "  def __init__(self):\n",
    "    # Keep a cache of every axis-name seen\n",
    "    self.shapes = {}\n",
    "\n",
    "  def __call__(self, tensor, names, broadcast=False):\n",
    "    if not tf.executing_eagerly():\n",
    "      return\n",
    "\n",
    "    parsed = einops.parse_shape(tensor, names)\n",
    "\n",
    "    for name, new_dim in parsed.items():\n",
    "      old_dim = self.shapes.get(name, None)\n",
    "\n",
    "      if (broadcast and new_dim == 1):\n",
    "        continue\n",
    "\n",
    "      if old_dim is None:\n",
    "        # If the axis name is new, add its length to the cache.\n",
    "        self.shapes[name] = new_dim\n",
    "        continue\n",
    "\n",
    "      if new_dim != old_dim:\n",
    "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
    "                         f\"    found: {new_dim}\\n\"\n",
    "                         f\"    expected: {old_dim}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:52.216336700Z",
     "start_time": "2023-12-19T20:49:52.186810200Z"
    }
   },
   "id": "1b1d41e5a166622d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1 - Getting the data\n",
    "\n",
    "Uses [Anki](http://www.manythings.org/anki/) dataset with translation pairs such as english-spanish text - more languages are available\n",
    "\n",
    "1. Download the dataset\n",
    "2. Add a start and end token to each sentence.\n",
    "1. Clean the sentences by removing special characters.\n",
    "1. Create a word index and reverse word index (dictionaries mapping from word → id and id → word).\n",
    "1. Pad each sentence to a maximum length\n",
    "\n",
    "### Download the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "126a783b12c128b6"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Download the file\n",
    "import pathlib\n",
    "local_data_path = local_data_path_root+ \"/data\"\n",
    "\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    cache_subdir=local_data_path,\n",
    "    extract=True)\n",
    "\n",
    "path_to_file = pathlib.Path(path_to_zip).parent/'spa-eng/spa.txt'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:52.289361900Z",
     "start_time": "2023-12-19T20:49:52.202344900Z"
    }
   },
   "id": "25399caa18fcb2cb"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "  text = path.read_text(encoding='utf-8')\n",
    "\n",
    "  lines = text.splitlines()\n",
    "  pairs = [line.split('\\t') for line in lines]\n",
    "\n",
    "  context = np.array([context for target, context in pairs])\n",
    "  target = np.array([target for target, context in pairs])\n",
    "\n",
    "  return target, context"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:52.306410300Z",
     "start_time": "2023-12-19T20:49:52.293353100Z"
    }
   },
   "id": "1417d518da552989"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.\n",
      "\n",
      "If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\n"
     ]
    }
   ],
   "source": [
    "target_raw, context_raw = load_data(path_to_file)\n",
    "print(context_raw[-1])\n",
    "print()\n",
    "print(target_raw[-1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:52.755235900Z",
     "start_time": "2023-12-19T20:49:52.307900400Z"
    }
   },
   "id": "df0018e2a2260ecd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare the dataset\n",
    "\n",
    "start with a tf.dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85c8d0c9f0fae90d"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(context_raw)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
    "\n",
    "train_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE))\n",
    "val_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:53.267499500Z",
     "start_time": "2023-12-19T20:49:52.758232800Z"
    }
   },
   "id": "3540950289fad5ff"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'Boston es mi casa.' b'Estoy ocupado ahora y no puedo jugar con vos.'\n",
      " b'Tom le dese\\xc3\\xb3 buena suerte a Mary.'\n",
      " b'\\xc2\\xbfQu\\xc3\\xa9 estamos haciendo?'\n",
      " b'Tom quer\\xc3\\xada despedir a Mary, pero John se lo impidi\\xc3\\xb3.'], shape=(5,), dtype=string)\n",
      "\n",
      "tf.Tensor(\n",
      "[b'Boston is my home.' b\"I am busy now and can't play with you.\"\n",
      " b'Tom wished Mary good luck.' b'What are we doing?'\n",
      " b'Tom wanted to fire Mary, but John stopped him.'], shape=(5,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for example_context_strings, example_target_strings in train_raw.take(1):\n",
    "  print(example_context_strings[:5])\n",
    "  print()\n",
    "  print(example_target_strings[:5])\n",
    "  break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:53.578102Z",
     "start_time": "2023-12-19T20:49:53.270000100Z"
    }
   },
   "id": "189fe63f5802ac68"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocess the text\n",
    "\n",
    "- standardization\n",
    "  - unicode normalization - split accented characters and replace compat chars with ascii equivalents  \n",
    "- vectorization\n",
    "  - handles vocabulary extraction and conversion of input text into token sequences   "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96aabcc98d18e1bf"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xc2\\xbfTodav\\xc3\\xada est\\xc3\\xa1 en casa?'\n",
      "b'\\xc2\\xbfTodavi\\xcc\\x81a esta\\xcc\\x81 en casa?'\n"
     ]
    }
   ],
   "source": [
    "example_text = tf.constant('¿Todavía está en casa?')\n",
    "\n",
    "print(example_text.numpy())\n",
    "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:53.637607700Z",
     "start_time": "2023-12-19T20:49:53.582604200Z"
    }
   },
   "id": "4ad3ca5df0b860bf"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def tf_lower_and_split_punct(text):\n",
    "  # Split accented characters.\n",
    "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
    "  text = tf.strings.lower(text)\n",
    "  # Keep space, a to z, and select punctuation.\n",
    "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
    "  # Add spaces around punctuation.\n",
    "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
    "  # Strip whitespace.\n",
    "  text = tf.strings.strip(text)\n",
    "\n",
    "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
    "  return text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:53.639607400Z",
     "start_time": "2023-12-19T20:49:53.598101100Z"
    }
   },
   "id": "9cc95e802d8302f6"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Todavía está en casa?\n",
      "[START] ¿ todavia esta en casa ? [END]\n"
     ]
    }
   ],
   "source": [
    "print(example_text.numpy().decode())\n",
    "print(tf_lower_and_split_punct(example_text).numpy().decode())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:53.695614700Z",
     "start_time": "2023-12-19T20:49:53.612616400Z"
    }
   },
   "id": "d53472744ad3a46d"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "max_vocab_size = 5000\n",
    "\n",
    "context_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size,\n",
    "    ragged=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:53.759125Z",
     "start_time": "2023-12-19T20:49:53.665608100Z"
    }
   },
   "id": "fbd97412ebccd794"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "['', '[UNK]', '[START]', '[END]', '.', 'que', 'de', 'el', 'a', 'no']"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
    "\n",
    "# Here are the first 10 words from the vocabulary:\n",
    "context_text_processor.get_vocabulary()[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:55.576489Z",
     "start_time": "2023-12-19T20:49:53.707126600Z"
    }
   },
   "id": "6136b8100d248c56"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "['', '[UNK]', '[START]', '[END]', '.', 'the', 'i', 'to', 'you', 'tom']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size,\n",
    "    ragged=True)\n",
    "\n",
    "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
    "target_text_processor.get_vocabulary()[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:57.254756Z",
     "start_time": "2023-12-19T20:49:55.576989300Z"
    }
   },
   "id": "3aa904d086488e79"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.RaggedTensor [[2, 137, 15, 24, 53, 4, 3],\n [2, 41, 340, 92, 33, 9, 55, 325, 27, 469, 4, 3],\n [2, 10, 28, 1073, 210, 533, 8, 32, 4, 3]]>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tokens = context_text_processor(example_context_strings)\n",
    "example_tokens[:3, :]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:57.360212800Z",
     "start_time": "2023-12-19T20:49:57.253757300Z"
    }
   },
   "id": "ff6e5daa07e1339f"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2 137  15  24  53   4   3]\n",
      "tf.Tensor([  2 137  15  24  53   4   3   0   0   0   0   0   0   0   0   0], shape=(16,), dtype=int64)\n",
      "['[START]' 'boston' 'es' 'mi' 'casa' '.' '[END]']\n"
     ]
    }
   ],
   "source": [
    "print(example_tokens[0].numpy())\n",
    "context_vocab = np.array(context_text_processor.get_vocabulary())\n",
    "tokens = context_vocab[example_tokens[0].numpy()]\n",
    "' '.join(tokens)\n",
    "print(example_tokens.to_tensor()[0])\n",
    "print(tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:57.404226700Z",
     "start_time": "2023-12-19T20:49:57.362702100Z"
    }
   },
   "id": "a44bde4e08203c6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "you can see from the above that the returned tensors are zero padded - these can be used to form a mask"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f394290bdaf4bf9"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 1.0, 'Mask')"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(example_tokens.to_tensor())\n",
    "plt.title('Token IDs')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
    "plt.title('Mask')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:57.767335500Z",
     "start_time": "2023-12-19T20:49:57.394216100Z"
    }
   },
   "id": "fa0ccc36bf5607f4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### process the dataset\n",
    "\n",
    "in the following function, (context, target) becomes ((context,target_in), target_out) for training\n",
    "keras expects (inputs, label) where here, (context, target_in) is the input, and target_out is the label\n",
    "the difference between _in and _out is that _out is shifted one character right, so at each location, the label is the next token (expected value)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6dc68a6ead29e8b"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def process_text(context, target):\n",
    "  context = context_text_processor(context).to_tensor()\n",
    "  target = target_text_processor(target)\n",
    "  targ_in = target[:,:-1].to_tensor()\n",
    "  targ_out = target[:,1:].to_tensor()\n",
    "  return (context, targ_in), targ_out\n",
    "\n",
    "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
    "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:57.979486400Z",
     "start_time": "2023-12-19T20:49:57.767836100Z"
    }
   },
   "id": "9c48bdce959ed46d"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2   10   17 3177   31  323    4    3    0    0]\n",
      "\n",
      "[   2    9 3377    7   93    4    0    0    0    0]\n",
      "[   9 3377    7   93    4    3    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
    "  print(ex_context_tok[0, :10].numpy()) \n",
    "  print()\n",
    "  print(ex_tar_in[0, :10].numpy()) \n",
    "  print(ex_tar_out[0, :10].numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:58.219647800Z",
     "start_time": "2023-12-19T20:49:57.983485900Z"
    }
   },
   "id": "586132968a73ef1d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2 - The encoder / decoder architecture and model\n",
    "\n",
    "two simplifications from the original attention-based translation model - typically unnecessary:\n",
    "- feeding state from encoder's RNN to the decoder's RNN\n",
    "- Feeding attention output back to the RNN input \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c98b59f19cc74593"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "UNITS = 256"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:58.252650200Z",
     "start_time": "2023-12-19T20:49:58.215645900Z"
    }
   },
   "id": "47592e41f927a42a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The encoder design\n",
    "\n",
    "since context sequence is constant, information can flow between any units in the encoder, so use a bidirectional RNN\n",
    "\n",
    "1. gets a list of token IDs\n",
    "2. looks up an embedding vector for each token\n",
    "3. processes the embeddings into a new sequence (using a bidirectional RNN\n",
    "4. returns the processed sequence -> attention head"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d97dfe438659a1aa"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, text_processor, units):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.text_processor = text_processor\n",
    "    self.vocab_size = text_processor.vocabulary_size()\n",
    "    self.units = units\n",
    "\n",
    "    # The embedding layer converts tokens to vectors\n",
    "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
    "                                               mask_zero=True)\n",
    "\n",
    "    # The RNN layer processes those vectors sequentially.\n",
    "    self.rnn = tf.keras.layers.Bidirectional(\n",
    "        merge_mode='sum',\n",
    "        layer=tf.keras.layers.GRU(units,\n",
    "                            # Return the sequence and state\n",
    "                            return_sequences=True,\n",
    "                            recurrent_initializer='glorot_uniform'))\n",
    "\n",
    "  def call(self, x):\n",
    "    shape_checker = ShapeChecker()\n",
    "    shape_checker(x, 'batch s')\n",
    "\n",
    "    # 2. The embedding layer looks up the embedding vector for each token.\n",
    "    x = self.embedding(x)\n",
    "    shape_checker(x, 'batch s units')\n",
    "\n",
    "    # 3. The GRU processes the sequence of embeddings.\n",
    "    x = self.rnn(x)\n",
    "    shape_checker(x, 'batch s units')\n",
    "\n",
    "    # 4. Returns the new sequence of embeddings.\n",
    "    return x\n",
    "\n",
    "  def convert_input(self, texts):\n",
    "    texts = tf.convert_to_tensor(texts)\n",
    "    if len(texts.shape) == 0:\n",
    "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
    "    context = self.text_processor(texts).to_tensor()\n",
    "    context = self(context)\n",
    "    return context"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:58.254147500Z",
     "start_time": "2023-12-19T20:49:58.236144100Z"
    }
   },
   "id": "98dd03eace5a465"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context tokens, shape (batch, s): (64, 21)\n",
      "Encoder output, shape (batch, s, units): (64, 21, 256)\n"
     ]
    }
   ],
   "source": [
    "# Encode the input sequence.\n",
    "encoder = Encoder(context_text_processor, UNITS)\n",
    "ex_context = encoder(ex_context_tok)\n",
    "\n",
    "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
    "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:58.569818900Z",
     "start_time": "2023-12-19T20:49:58.265137200Z"
    }
   },
   "id": "a1eae5c7a7177d77"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:49:58.584341Z",
     "start_time": "2023-12-19T20:49:58.572843900Z"
    }
   },
   "id": "2c6f1d541b11f4f5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
